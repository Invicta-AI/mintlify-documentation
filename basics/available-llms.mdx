---
title: "Available LLMs"
icon: brain
---

## Introduction

Our platform provides access to a diverse range of Language Learning Models (LLMs) from leading AI research companies such as OpenAI, Anthropic, Meta, and Mistral. These models are integral to the function of AI agents within our ecosystem, each offering unique capabilities and performance characteristics tailored to different user needs.

Below is an overview of the LLMs currently available on our platform, including their Elo ratings, speed metrics, and compute point consumption.

## Available Models

| Model Name     | Provider   | Elo Rating üèÜ | Context Window Size | CPs / 1K Tokens | Tool Use |
| -------------- | ---------- | ------------- | ------------------- | --------------- | -------- |
| GPT-4o         | OpenAI     | 1287          | 128,000 tokens      | 1.16667         | Yes      |
| Claude 3.5     | Anthropic  | 1271          | 200,000 tokens      | 1.16667         | No       |
| GPT-4 Turbo    | OpenAI     | 1257          | 128,000 tokens      | 1.66667         | Yes      |
| Claude 3       | Anthropic  | 1249          | 200,000 tokens      | 1.16667         | No       |
| Llama3-70B     | Meta       | 1246          | 8,192 tokens        | 1.11667         | No       |
| GPT-4o mini    | OpenAI     | 1238          | 128,000 tokens      | 0.08333         | Yes      |
| Mistral Large  | Mistral AI | 1156          | 32,000 tokens       | 1.06668         | Yes      |
| Claude 2       | Anthropic  | 1119          | 200,000 tokens      | 4.16667         | No       |
| Mistral Small  | Mistral AI | 1114          | 32,000 tokens       | 0.26667         | Yes      |
| Claude Instant | Anthropic  | 1109          | 100,000 tokens      | 0.41667         | No       |

## Elo Rating / Intelligence Points

We have adapted the Elo rating system system to rate the intelligence points of LLMs based on their performance in natural language understanding and generation tasks. The ratings are sourced from the LMSYS Chatbot Arena Leaderboard, which is a crowdsourced open platform for evaluating LLMs through human preference votes. For more details, please visit: [LMSYS Chatbot Arena Leaderboard](https://chat.lmsys.org/?leaderboard).

## Tool Use

Certain LLMs on our platform support tool use capabilities. This feature allows AI agents to perform a variety of tasks beyond text generation, enabling them to interact dynamically with external systems and datasets. As the field of AI continues to advance, we anticipate that tool use capabilities will become standard across all LLMs.

## Speed Metrics

Speed is determined by two factors:

- Time to first token generation: The latency from when a prompt is sent to when the first piece of output is received.
- Tokens per second generation: The rate at which the model generates tokens after the initial response has begun.

These metrics are crucial for applications that require real-time interaction or high throughput.

## Credits

As explained previously, credits are a measure of resource consumption when utilizing LLMs. They correlate with the complexity and size of the models, where lighter models consume fewer points compared to more robust models like GPT-4o/Claude-3.5.

## Selecting the Right LLM for Your Needs

Choosing an appropriate LLM depends on several factors, including:

1. System message alignment and performance/speed requirements.
2. Distinct writing styles preferred for your application.
3. Model responsiveness and speed for real-time interactions.
4. Language proficiency if operating in languages other than English.

Our platform's flexibility allows users to tailor AI agents for specialized tasks by selecting from these varied LLMs.

## Conclusion

Understanding the unique attributes and capabilities of each available LLM on our platform will enable you to make informed decisions about which model best suits your needs. Whether you prioritize eloquence, speed, multilingual support, or cost-effectiveness in terms of credits, our selection aims to meet a comprehensive range of requirements.
